{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832005e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\n",
      "RAW : C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\raw\n",
      "PROC: C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\processed\n",
      "DOCS: C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\docs\n",
      "CONF: C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\config\\categories.yaml\n"
     ]
    }
   ],
   "source": [
    "# ===== 1) CONFIG =====\n",
    "from pathlib import Path\n",
    "\n",
    "# >>> Update BASE if your path is different <<<\n",
    "BASE = Path(r\"C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\scripts\")\n",
    "\n",
    "PATH_RAW  = BASE / \"data\" / \"raw\"\n",
    "PATH_PROC = BASE / \"data\" / \"processed\"\n",
    "PATH_DOCS = BASE / \"docs\"\n",
    "PATH_CONF = BASE / \"config\" / \"categories.yaml\"\n",
    "\n",
    "# Ensure folders exist\n",
    "for p in (PATH_RAW, PATH_PROC, PATH_DOCS):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"BASE:\", BASE)\n",
    "print(\"RAW :\", PATH_RAW)\n",
    "print(\"PROC:\", PATH_PROC)\n",
    "print(\"DOCS:\", PATH_DOCS)\n",
    "print(\"CONF:\", PATH_CONF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f0146360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 2) REQUIREMENTS =====\n",
    "# If PyYAML isn't installed, uncomment and run once:\n",
    "# %pip install pyyaml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0068f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 3) HELPERS =====\n",
    "\n",
    "def safe_number(x):\n",
    "    '''Convert to float safely; handles $ and commas.'''\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x)\n",
    "    s = str(x).strip().replace(\"$\",\"\").replace(\",\",\"\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def normalize_date(s):\n",
    "    '''Parse many date formats -> pandas.Timestamp (naive).'''\n",
    "    return pd.to_datetime(s, errors=\"coerce\")\n",
    "\n",
    "def derive_merchant_key(desc: str) -> str:\n",
    "    '''Create a stable merchant key from raw description.'''\n",
    "    if pd.isna(desc):\n",
    "        return \"\"\n",
    "    s = str(desc).upper()\n",
    "    # Remove long digit blocks and extra spaces\n",
    "    import re\n",
    "    s = re.sub(r\"\\d{3,}\", \" \", s)\n",
    "    s = re.sub(r\"[^A-Z\\s&\\-']\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s[:64]\n",
    "\n",
    "def load_yaml_mapping(path_yaml: Path):\n",
    "    if not path_yaml.exists():\n",
    "        print(f\"[WARN] YAML not found at {path_yaml}. Proceeding with empty mapping.\")\n",
    "        return {}\n",
    "    with open(path_yaml, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = yaml.safe_load(f) or {}\n",
    "    return data\n",
    "\n",
    "def apply_yaml_mapping(df: pd.DataFrame, ymap: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Accepts flexible YAML formats:\n",
    "      Simple:  APPLEBEES: dining\n",
    "      Rich:    APPLEBEES: {display_name: APPLEBEES, category: dining, tags: [sitdown], is_necessity: false}\n",
    "      Weird:   NUMERICKEY: 1   -> coerced to category \"1\"\n",
    "    Keys should correspond to df['merchant_key'] (recommended).\n",
    "    \"\"\"\n",
    "    # If someone provided a list at the top level, coerce to dict by taking entries with 'key' fields\n",
    "    if isinstance(ymap, list):\n",
    "        tmp = {}\n",
    "        for item in ymap:\n",
    "            if isinstance(item, dict):\n",
    "                # try common shapes: {'key': 'APPLEBEES', 'category': 'dining', ...} or {'APPLEBEES': {...}}\n",
    "                if \"key\" in item:\n",
    "                    tmp[str(item[\"key\"]).upper()] = {k: v for k, v in item.items() if k != \"key\"}\n",
    "                else:\n",
    "                    # take first key in nested mapping\n",
    "                    for k, v in item.items():\n",
    "                        tmp[str(k).upper()] = v\n",
    "            # ignore non-dict list items\n",
    "        ymap = tmp\n",
    "\n",
    "    # Build normalized mapping\n",
    "    direct = {}\n",
    "    for k, v in (ymap or {}).items():\n",
    "        k_up = str(k).upper()\n",
    "\n",
    "        if isinstance(v, dict):\n",
    "            display = str(v.get(\"display_name\", k_up)).upper()\n",
    "            category = v.get(\"category\", None)\n",
    "            tags_val = v.get(\"tags\", [])\n",
    "            if isinstance(tags_val, (list, tuple)):\n",
    "                tags_text = \",\".join(map(str, tags_val))\n",
    "            else:\n",
    "                tags_text = str(tags_val) if tags_val is not None else \"\"\n",
    "            is_necessity = bool(v.get(\"is_necessity\", False))\n",
    "        elif isinstance(v, str):\n",
    "            display = k_up\n",
    "            category = v\n",
    "            tags_text = \"\"\n",
    "            is_necessity = False\n",
    "        elif v is None:\n",
    "            display = k_up\n",
    "            category = None\n",
    "            tags_text = \"\"\n",
    "            is_necessity = False\n",
    "        else:\n",
    "            # numbers / other types: treat as category string\n",
    "            display = k_up\n",
    "            category = str(v)\n",
    "            tags_text = \"\"\n",
    "            is_necessity = False\n",
    "\n",
    "        direct[k_up] = {\n",
    "            \"display_name_final\": display,\n",
    "            \"category_final\": category,\n",
    "            \"tags_final\": tags_text,\n",
    "            \"is_necessity\": is_necessity,\n",
    "        }\n",
    "\n",
    "    out = df.copy()\n",
    "\n",
    "    # Ensure expected columns exist\n",
    "    for col, default in [\n",
    "        (\"display_name_final\",\"\"),\n",
    "        (\"category_final\",\"\"),\n",
    "        (\"tags_final\",\"\"),\n",
    "        (\"is_necessity\", False),\n",
    "        (\"source_final\",\"\"),\n",
    "        (\"confidence_final\",\"\"),\n",
    "    ]:\n",
    "        if col not in out.columns:\n",
    "            out[col] = default\n",
    "\n",
    "    # Apply mapping by merchant_key\n",
    "    def map_row(row):\n",
    "        key = str(row.get(\"merchant_key\",\"\")).upper().strip()\n",
    "        m = direct.get(key)\n",
    "        if m:\n",
    "            row[\"display_name_final\"] = m[\"display_name_final\"]\n",
    "            row[\"category_final\"]     = m[\"category_final\"]\n",
    "            row[\"tags_final\"]         = m[\"tags_final\"]\n",
    "            row[\"is_necessity\"]       = m[\"is_necessity\"]\n",
    "            row[\"source_final\"]       = \"yaml\"\n",
    "            row[\"confidence_final\"]   = \"yaml\"\n",
    "        return row\n",
    "\n",
    "    return out.apply(map_row, axis=1)\n",
    "\n",
    "\n",
    "def write_unknowns(df: pd.DataFrame, path_out: Path):\n",
    "    unk = df[(df[\"display_name_final\"]==\"\") | (df[\"category_final\"]==\"\")].copy()\n",
    "    if not unk.empty:\n",
    "        path_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "        cols = [c for c in [\"date\",\"account\",\"description\",\"merchant_key\",\"amount\"] if c in unk.columns]\n",
    "        unk[cols].to_csv(path_out, index=False)\n",
    "        print(f\"[INFO] Unknown merchants written → {path_out} ({len(unk)} rows)\")\n",
    "    else:\n",
    "        print(\"[INFO] No unknown merchants to review.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14c22af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 6 raw file(s):\n",
      "   - chase_amazonprime_6m.CSV\n",
      "   - chase_checking_6m.CSV\n",
      "   - chase_flex_6m.CSV\n",
      "   - discover_credit_ytd.csv\n",
      "   - ssscu_checking_6m.CSV\n",
      "   - ssscu_credit_6m.CSV\n",
      "[READ] chase_amazonprime_6m.CSV | sep=',' enc=utf-8-sig header_row=0 shape=(84, 7)\n",
      "[READ] chase_checking_6m.CSV | sep=',' enc=utf-8-sig header_row=0 shape=(50, 7)\n",
      "[READ] chase_flex_6m.CSV | sep=',' enc=utf-8-sig header_row=0 shape=(12, 7)\n",
      "[READ] discover_credit_ytd.csv | sep=',' enc=utf-8-sig header_row=0 shape=(78, 5)\n",
      "[READ] ssscu_checking_6m.CSV | sep=',' enc=utf-8-sig header_row=3 shape=(230, 11)\n",
      "[READ] ssscu_credit_6m.CSV | sep=',' enc=utf-8-sig header_row=3 shape=(15, 11)\n",
      "[INFO] Raw combined rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account</th>\n",
       "      <th>description</th>\n",
       "      <th>amount</th>\n",
       "      <th>source_file</th>\n",
       "      <th>merchant_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, account, description, amount, source_file, merchant_key]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 4) INGEST RAW FILES (robust) =====\n",
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "files = sorted(PATH_RAW.glob(\"*.csv\"))\n",
    "if not files:\n",
    "    print(f\"[WARN] No raw CSVs found in {PATH_RAW}. Add files and re-run.\")\n",
    "else:\n",
    "    print(f\"[INFO] Found {len(files)} raw file(s):\")\n",
    "    for f in files: print(\"   -\", f.name)\n",
    "\n",
    "def sniff_delimiter_and_header(text: str):\n",
    "    \"\"\"\n",
    "    Try to detect delimiter and header row index.\n",
    "    Returns (delimiter, header_row_idx). If unsure, defaults to (',', 0).\n",
    "    \"\"\"\n",
    "    # Try csv.Sniffer on a sample\n",
    "    sample = text[:100_000]\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(sample, delimiters=[',',';','\\t','|'])\n",
    "        delim = dialect.delimiter\n",
    "    except Exception:\n",
    "        # Fallback to heuristics\n",
    "        counts = {d: sample.count(d) for d in [',',';','\\t','|']}\n",
    "        delim = max(counts, key=counts.get)\n",
    "\n",
    "    # Find header row (look for a row containing any of these canonical column names)\n",
    "    header_candidates = [\"date\",\"transaction date\",\"posted date\",\"post date\",\"description\",\"details\",\"memo\",\"amount\",\"debit\",\"credit\"]\n",
    "    lines = sample.splitlines()\n",
    "    header_idx = 0\n",
    "    for i, line in enumerate(lines[:50]):  # scan first 50 lines for a header\n",
    "        parts = [p.strip().lower() for p in line.split(delim)]\n",
    "        if any(h in parts for h in header_candidates):\n",
    "            header_idx = i\n",
    "            break\n",
    "    return delim, header_idx\n",
    "\n",
    "def robust_read_csv(path):\n",
    "    # Try a couple encodings\n",
    "    for enc in [\"utf-8-sig\", \"utf-16\", \"latin-1\", \"utf-8\"]:\n",
    "        try:\n",
    "            txt = path.read_text(encoding=enc, errors=\"ignore\")\n",
    "            delim, header_idx = sniff_delimiter_and_header(txt)\n",
    "            df = pd.read_csv(\n",
    "                StringIO(txt),\n",
    "                sep=delim,\n",
    "                header=header_idx,\n",
    "                engine=\"python\",            # more forgiving\n",
    "                on_bad_lines=\"skip\",        # skip malformed lines\n",
    "                dtype=str                   # keep raw as text; we normalize later\n",
    "            )\n",
    "            # Drop any leading non-data rows above header\n",
    "            if header_idx > 0:\n",
    "                df = df.reset_index(drop=True)\n",
    "            return df, delim, enc, header_idx\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    raise last_err\n",
    "\n",
    "frames = []\n",
    "for f in files:\n",
    "    try:\n",
    "        df, delim, enc, hdr = robust_read_csv(f)\n",
    "        print(f\"[READ] {f.name} | sep='{delim}' enc={enc} header_row={hdr} shape={df.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] {f.name} — could not parse ({e})\")\n",
    "        continue\n",
    "\n",
    "    # Normalize column names\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    # Flexible column detection\n",
    "    candidates = {\n",
    "        \"date\":        [\"date\",\"transaction date\",\"transaction_date\",\"posted date\",\"post date\",\"posted_date\",\"date posted\"],\n",
    "        \"account\":     [\"account\",\"account name\",\"account_name\",\"acct\",\"card\"],\n",
    "        \"description\": [\"description\",\"details\",\"memo\",\"merchant\",\"name\",\"narrative\",\"transaction description\"],\n",
    "        \"amount\":      [\"amount\",\"transaction amount\",\"transaction_amount\",\"debit\",\"credit\",\"amt\",\"value\"]\n",
    "    }\n",
    "    pick = {}\n",
    "    for tgt, opts in candidates.items():\n",
    "        for c in opts:\n",
    "            if c in df.columns:\n",
    "                pick[tgt] = c; break\n",
    "\n",
    "    # Some exports list debit/credit separately; combine into a single signed amount if needed\n",
    "    if \"amount\" not in pick:\n",
    "        if \"debit\" in df.columns or \"credit\" in df.columns:\n",
    "            amt = pd.Series([np.nan]*len(df))\n",
    "            if \"debit\" in df.columns:\n",
    "                amt = amt.fillna(df[\"debit\"])\n",
    "            if \"credit\" in df.columns:\n",
    "                # credits as negative\n",
    "                cr = pd.to_numeric(df[\"credit\"].str.replace(\",\",\"\", regex=False), errors=\"coerce\") * -1\n",
    "                amt = amt.fillna(cr)\n",
    "            df[\"__amount_combined__\"] = amt\n",
    "            pick[\"amount\"] = \"__amount_combined__\"\n",
    "\n",
    "    tmp = pd.DataFrame({\n",
    "        \"date\":        df[pick.get(\"date\")]        if \"date\" in pick        else np.nan,\n",
    "        \"account\":     df[pick.get(\"account\")]     if \"account\" in pick     else \"unknown\",\n",
    "        \"description\": df[pick.get(\"description\")] if \"description\" in pick else df.get(\"description\",\"\"),\n",
    "        \"amount\":      df[pick.get(\"amount\")]      if \"amount\" in pick      else df.get(\"amount\", np.nan),\n",
    "    })\n",
    "    tmp[\"source_file\"] = f.name\n",
    "\n",
    "    # Normalize types\n",
    "    tmp[\"date\"] = tmp[\"date\"].apply(normalize_date)\n",
    "    tmp[\"amount\"] = tmp[\"amount\"].apply(safe_number)\n",
    "\n",
    "# Make charges positive, credits/refunds negative — per-file\n",
    "amt = pd.to_numeric(tmp[\"amount\"], errors=\"coerce\")\n",
    "neg_ratio = (amt < 0).mean()\n",
    "median_amt = amt.median(skipna=True)\n",
    "\n",
    "# If most rows are negative (common for Chase exports), flip\n",
    "if (neg_ratio > 0.6) or (pd.notna(median_amt) and median_amt < 0):\n",
    "    tmp[\"amount\"] = -amt\n",
    "else:\n",
    "    tmp[\"amount\"] = amt\n",
    "\n",
    "    # In case the export uses \"CR\"/\"DR\" signs embedded in description or amount, try to detect\n",
    "    # (optional; comment out if not needed)\n",
    "    # Example: if description contains \"CREDIT\" and amount is positive, flip sign\n",
    "    mask_credit_hint = tmp[\"description\"].str.upper().str.contains(\"CREDIT|REFUND|PAYMENT\", na=False)\n",
    "    tmp.loc[mask_credit_hint & (tmp[\"amount\"] > 0), \"amount\"] *= -1\n",
    "\n",
    "    # Merchant key\n",
    "    tmp[\"merchant_key\"] = tmp[\"description\"].apply(derive_merchant_key)\n",
    "\n",
    "    frames.append(tmp)\n",
    "\n",
    "raw_all = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame(columns=[\"date\",\"account\",\"description\",\"amount\",\"merchant_key\",\"source_file\"])\n",
    "raw_all = raw_all.dropna(subset=[\"date\",\"amount\"])\n",
    "print(f\"[INFO] Raw combined rows: {len(raw_all):,}\")\n",
    "raw_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c8eb7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No unknown merchants to review.\n",
      "[OK] transactions_enriched.csv written → C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\processed\\transactions_enriched.csv  (0 rows)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>account</th>\n",
       "      <th>description</th>\n",
       "      <th>merchant_key</th>\n",
       "      <th>display_name_final</th>\n",
       "      <th>category_final</th>\n",
       "      <th>tags_final</th>\n",
       "      <th>confidence_final</th>\n",
       "      <th>source_final</th>\n",
       "      <th>amount</th>\n",
       "      <th>is_necessity</th>\n",
       "      <th>is_non_spend_flow</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, account, description, merchant_key, display_name_final, category_final, tags_final, confidence_final, source_final, amount, is_necessity, is_non_spend_flow, source_file]\n",
       "Index: []"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 5) ENRICH VIA YAML =====\n",
    "ymap = load_yaml_mapping(PATH_CONF)\n",
    "enriched = apply_yaml_mapping(raw_all, ymap)\n",
    "\n",
    "# Mark non-spend flows\n",
    "patterns_non_spend = [\"PAYMENT\",\"DIRECTPAY\",\"TRANSFER\",\"CREDIT\",\"REFUND\"]\n",
    "def non_spend_flag(desc, amt):\n",
    "    s = str(desc).upper()\n",
    "    if any(p in s for p in patterns_non_spend): return True\n",
    "    if amt < 0: return True\n",
    "    return False\n",
    "\n",
    "enriched[\"is_non_spend_flow\"] = enriched.apply(lambda r: non_spend_flag(r[\"description\"], r[\"amount\"]), axis=1)\n",
    "\n",
    "# Save unknowns for mapping\n",
    "write_unknowns(enriched, PATH_DOCS / \"review_unknowns.csv\")\n",
    "\n",
    "# Stable schema/order\n",
    "cols_order = [\n",
    "    \"date\",\"account\",\"description\",\"merchant_key\",\n",
    "    \"display_name_final\",\"category_final\",\"tags_final\",\n",
    "    \"confidence_final\",\"source_final\",\"amount\",\n",
    "    \"is_necessity\",\"is_non_spend_flow\",\"source_file\"\n",
    "]\n",
    "for c in cols_order:\n",
    "    if c not in enriched.columns:\n",
    "        if c in [\"is_necessity\",\"is_non_spend_flow\"]:\n",
    "            enriched[c] = False\n",
    "        else:\n",
    "            enriched[c] = \"\"\n",
    "\n",
    "enriched = enriched[cols_order].sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "out_tx = PATH_PROC / \"transactions_enriched.csv\"\n",
    "enriched.to_csv(out_tx, index=False)\n",
    "print(f\"[OK] transactions_enriched.csv written → {out_tx}  ({len(enriched):,} rows)\")\n",
    "enriched.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0be9d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] ai_insights.csv written → C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\processed\\ai_insights.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_start</th>\n",
       "      <th>total_outflows</th>\n",
       "      <th>prev</th>\n",
       "      <th>mom_outflows_pct</th>\n",
       "      <th>top_category</th>\n",
       "      <th>amount_x</th>\n",
       "      <th>top_merchant</th>\n",
       "      <th>amount_y</th>\n",
       "      <th>subscriptions_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [month_start, total_outflows, prev, mom_outflows_pct, top_category, amount_x, top_merchant, amount_y, subscriptions_estimate]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 6) AI KPIs (ai_insights.csv) =====\n",
    "tx = pd.read_csv(PATH_PROC / \"transactions_enriched.csv\")\n",
    "tx[\"date\"] = pd.to_datetime(tx[\"date\"], errors=\"coerce\")\n",
    "tx[\"amount\"] = pd.to_numeric(tx[\"amount\"], errors=\"coerce\")\n",
    "tx = tx.dropna(subset=[\"date\",\"amount\"])\n",
    "\n",
    "spend = tx[tx[\"amount\"] > 0].copy()\n",
    "spend[\"month_start\"] = spend[\"date\"].values.astype(\"datetime64[M]\")\n",
    "\n",
    "monthly = (spend.groupby(\"month_start\", as_index=False)\n",
    "           .agg(total_outflows=(\"amount\",\"sum\"))\n",
    "           .sort_values(\"month_start\"))\n",
    "\n",
    "monthly[\"prev\"] = monthly[\"total_outflows\"].shift(1)\n",
    "monthly[\"mom_outflows_pct\"] = ((monthly[\"total_outflows\"] - monthly[\"prev\"]) / monthly[\"prev\"]).replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "# Top category\n",
    "top_cat = (spend.groupby([\"month_start\",\"category_final\"], as_index=False)[\"amount\"].sum()\n",
    "           .sort_values([\"month_start\",\"amount\"], ascending=[True, False])\n",
    "           .drop_duplicates(\"month_start\")\n",
    "           .rename(columns={\"category_final\":\"top_category\"}))\n",
    "\n",
    "# Top merchant\n",
    "top_merch = (spend.groupby([\"month_start\",\"display_name_final\"], as_index=False)[\"amount\"].sum()\n",
    "             .sort_values([\"month_start\",\"amount\"], ascending=[True, False])\n",
    "             .drop_duplicates(\"month_start\")\n",
    "             .rename(columns={\"display_name_final\":\"top_merchant\"}))\n",
    "\n",
    "monthly = monthly.merge(top_cat, on=\"month_start\", how=\"left\").merge(top_merch, on=\"month_start\", how=\"left\")\n",
    "\n",
    "# Subscription estimate = tags contain \"subscription\" OR recurring merchant >= 3 months\n",
    "def to_text(x):\n",
    "    if isinstance(x, (list, tuple, set)):\n",
    "        return \",\".join(map(str, x))\n",
    "    if pd.isna(x): return \"\"\n",
    "    return str(x)\n",
    "\n",
    "if \"tags_final\" not in spend.columns:\n",
    "    spend[\"tags_final\"] = \"\"\n",
    "spend[\"tags_text\"] = spend[\"tags_final\"].apply(to_text).str.lower()\n",
    "spend[\"is_subscription_like\"] = spend[\"tags_text\"].str.contains(\"subscription\", na=False)\n",
    "\n",
    "rec_counts  = spend.groupby([\"display_name_final\",\"month_start\"]).size().reset_index(name=\"n\")\n",
    "rec_months  = rec_counts.groupby(\"display_name_final\")[\"month_start\"].nunique()\n",
    "rec_merchants = set(rec_months[rec_months >= 3].index)\n",
    "spend[\"is_subscription_like\"] = spend[\"is_subscription_like\"] | spend[\"display_name_final\"].isin(rec_merchants)\n",
    "\n",
    "subs = (spend[spend[\"is_subscription_like\"]]\n",
    "        .groupby(\"month_start\", as_index=False)[\"amount\"].sum()\n",
    "        .rename(columns={\"amount\":\"subscriptions_estimate\"}))\n",
    "\n",
    "monthly = monthly.merge(subs, on=\"month_start\", how=\"left\")\n",
    "monthly[\"subscriptions_estimate\"] = monthly[\"subscriptions_estimate\"].fillna(0.0)\n",
    "\n",
    "out_ai = PATH_PROC / \"ai_insights.csv\"\n",
    "monthly.to_csv(out_ai, index=False)\n",
    "print(f\"[OK] ai_insights.csv written → {out_ai}\")\n",
    "monthly.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "60fd52de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] ai_anomalies.csv written → C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\processed\\ai_anomalies.csv  (rows: 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>display_name_final</th>\n",
       "      <th>category_final</th>\n",
       "      <th>amount</th>\n",
       "      <th>zscore</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, display_name_final, category_final, amount, zscore, reason]\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 7) Anomalies (ai_anomalies.csv) =====\n",
    "def zscore(series):\n",
    "    mu = series.mean()\n",
    "    sd = series.std(ddof=0)\n",
    "    if pd.isna(sd) or sd == 0:\n",
    "        return pd.Series([0]*len(series), index=series.index)\n",
    "    return (series - mu) / sd\n",
    "\n",
    "spend[\"merchant_z\"] = spend.groupby(\"display_name_final\")[\"amount\"].transform(zscore)\n",
    "anoms = spend[spend[\"merchant_z\"].abs() >= 2.5].copy()\n",
    "anoms[\"reason\"] = anoms.apply(lambda r: f\"{abs(r['merchant_z']):.1f}σ vs usual at {r['display_name_final']}\", axis=1)\n",
    "\n",
    "anoms_out = anoms[[\"date\",\"display_name_final\",\"category_final\",\"amount\",\"merchant_z\",\"reason\"]].rename(columns={\"merchant_z\":\"zscore\"})\n",
    "out_anoms = PATH_PROC / \"ai_anomalies.csv\"\n",
    "anoms_out.to_csv(out_anoms, index=False)\n",
    "print(f\"[OK] ai_anomalies.csv written → {out_anoms}  (rows: {len(anoms_out)})\")\n",
    "anoms_out.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a03a16c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] ai_forecast.csv written → C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\processed\\ai_forecast.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month_start</th>\n",
       "      <th>spend_point_est</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M Moving Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M Moving Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-12-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3M Moving Average</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  month_start  spend_point_est  lower  upper             method\n",
       "0  2025-10-01              0.0    0.0    0.0  3M Moving Average\n",
       "1  2025-11-01              0.0    0.0    0.0  3M Moving Average\n",
       "2  2025-12-01              0.0    0.0    0.0  3M Moving Average"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 8) Forecast (ai_forecast.csv) =====\n",
    "ms = (monthly.set_index(\"month_start\")[[\"total_outflows\"]].asfreq(\"MS\"))\n",
    "ma = ms.rolling(window=3, min_periods=1).mean().iloc[-1, 0] if not ms.empty else 0.0\n",
    "\n",
    "projections = []\n",
    "last = ms.index.max() if not ms.empty else pd.Timestamp(\"today\").to_period(\"M\").to_timestamp()\n",
    "for i in range(1, 4):\n",
    "    m = last + pd.offsets.MonthBegin(i)\n",
    "    point = float(ma)\n",
    "    projections.append({\n",
    "        \"month_start\": m.date().isoformat(),\n",
    "        \"spend_point_est\": point,\n",
    "        \"lower\": point * 0.9,\n",
    "        \"upper\": point * 1.1,\n",
    "        \"method\": \"3M Moving Average\"\n",
    "    })\n",
    "\n",
    "fc_df = pd.DataFrame(projections)\n",
    "out_fc = PATH_PROC / \"ai_forecast.csv\"\n",
    "fc_df.to_csv(out_fc, index=False)\n",
    "print(f\"[OK] ai_forecast.csv written → {out_fc}\")\n",
    "fc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b43db8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] ai_summary.csv written → C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\processed\\ai_summary.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== 9) AI Summary CSV (ai_summary.csv) =====\n",
    "rows = []\n",
    "for _, r in monthly.iterrows():\n",
    "    ms = pd.to_datetime(r[\"month_start\"]).date().isoformat()\n",
    "    headline = f\"Spending {float(r['mom_outflows_pct']):+.0%} vs last month; top category: {r.get('top_category','—')}; top merchant: {r.get('top_merchant','—')}.\"\n",
    "    bullets = [f\"Subscriptions estimated: ${float(r.get('subscriptions_estimate', 0.0)):,.0f}\"]\n",
    "    rows.append({\"month_start\": ms, \"headline\": headline, \"bullets\": \" • \".join(bullets)})\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "out_sum = PATH_PROC / \"ai_summary.csv\"\n",
    "summary_df.to_csv(out_sum, index=False)\n",
    "print(f\"[OK] ai_summary.csv written → {out_sum}\")\n",
    "summary_df.tail()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Tools)",
   "language": "python",
   "name": "ai-tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
