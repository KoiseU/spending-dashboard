{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1881a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[V6NJvaWpwgtPd56vnMAbFKxraAkqKbTWDQ5lk] +386 / ~0 / -0 | cursor updated\n",
      "✔ Silver written (772 rows) & cursors saved\n",
      "\n",
      "=== RUN SUMMARY ===\n",
      "Silver rows:  772\n",
      "Gold rows:    772\n",
      "Unknowns:     12  → review_unknowns.csv\n",
      "Wrote Gold:   C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\processed\\transactions_enriched.csv\n",
      "Cursors:      C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\config\\plaid_cursors.json\n",
      "Deltas:       +386 / ~0 / -0\n",
      "✅ Done.\n"
     ]
    }
   ],
   "source": [
    "# One-Click Runner: Plaid sync → Silver → Gold (+ cursors, summary)\n",
    "\n",
    "import os, re, json, yaml\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "REPO = Path(r\"C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\").resolve()\n",
    "ENV_EXPECTED = \"sandbox\"  # change to \"production\" when you switch\n",
    "KEEP_PENDING = False      # leave False so we use posted transactions only\n",
    "# ----------------------------\n",
    "\n",
    "# Paths\n",
    "DATA = REPO / \"data\"\n",
    "RAW = DATA / \"raw\"\n",
    "INTERIM = DATA / \"interim\"\n",
    "PROCESSED = DATA / \"processed\"\n",
    "DOCS = REPO / \"docs\"\n",
    "CONFIG = REPO / \"config\"\n",
    "for p in [RAW, INTERIM, PROCESSED, DOCS, CONFIG]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SILVER    = INTERIM / \"transactions_canonical.csv\"\n",
    "ENRICHED  = PROCESSED / \"transactions_enriched.csv\"\n",
    "UNKNOWN   = DOCS / \"review_unknowns.csv\"\n",
    "ITEMS_JSON   = CONFIG / \"plaid_items.json\"\n",
    "CURSORS_JSON = CONFIG / \"plaid_cursors.json\"\n",
    "YAML_PATH    = CONFIG / \"categories.yaml\"\n",
    "\n",
    "# Load env\n",
    "load_dotenv(REPO / \".env\")\n",
    "if (os.getenv(\"PLAID_ENV\") or \"\").lower() != ENV_EXPECTED:\n",
    "    print(f\"⚠️ PLAID_ENV is '{os.getenv('PLAID_ENV')}', expected '{ENV_EXPECTED}'. Continue if intentional.\")\n",
    "\n",
    "# Plaid client\n",
    "from plaid.configuration import Configuration, Environment\n",
    "from plaid.api import plaid_api\n",
    "from plaid import ApiClient\n",
    "from plaid.model.transactions_sync_request import TransactionsSyncRequest\n",
    "from plaid.model.transactions_sync_request_options import TransactionsSyncRequestOptions\n",
    "\n",
    "env_map = {\"sandbox\": Environment.Sandbox, \"production\": Environment.Production}\n",
    "client = plaid_api.PlaidApi(ApiClient(Configuration(\n",
    "    host=env_map[(os.getenv(\"PLAID_ENV\") or \"sandbox\").lower()],\n",
    "    api_key={\"clientId\": os.getenv(\"PLAID_CLIENT_ID\"), \"secret\": os.getenv(\"PLAID_SECRET\")},\n",
    ")))\n",
    "\n",
    "# Load config\n",
    "assert ITEMS_JSON.exists(),  \"Missing config/plaid_items.json\"\n",
    "items   = json.loads(ITEMS_JSON.read_text(encoding=\"utf-8\")).get(\"items\", [])\n",
    "cursors = json.loads(CURSORS_JSON.read_text(encoding=\"utf-8\")).get(\"transactions\", {}) if CURSORS_JSON.exists() else {}\n",
    "\n",
    "# Load Silver (if any)\n",
    "if SILVER.exists():\n",
    "    silver = pd.read_csv(SILVER, dtype=str)\n",
    "else:\n",
    "    silver = pd.DataFrame(columns=[\n",
    "        \"transaction_id\",\"item_id\",\"account_id\",\"date\",\"name\",\"merchant_name\",\"amount\",\"pending\"\n",
    "    ])\n",
    "silver[\"transaction_id\"] = silver[\"transaction_id\"].astype(str)\n",
    "\n",
    "def upsert_rows(df, rows):\n",
    "    if not rows: return df\n",
    "    add = pd.DataFrame(rows)\n",
    "    if add.empty: return df\n",
    "    add[\"transaction_id\"] = add[\"transaction_id\"].astype(str)\n",
    "    df = df[~df[\"transaction_id\"].isin(add[\"transaction_id\"])]\n",
    "    return pd.concat([df, add], ignore_index=True)\n",
    "\n",
    "def delete_rows(df, removed_ids):\n",
    "    if not removed_ids: return df\n",
    "    ids = pd.Series([r[\"transaction_id\"] for r in removed_ids], dtype=str)\n",
    "    return df[~df[\"transaction_id\"].isin(ids)]\n",
    "\n",
    "# ---------- STAGE 1: Sync → update Silver ----------\n",
    "total_added = total_modified = total_removed = 0\n",
    "next_cursors = {}\n",
    "\n",
    "for it in items:\n",
    "    item_id = it[\"item_id\"]; token = it[\"access_token\"]\n",
    "    cursor  = cursors.get(item_id, \"\")\n",
    "    latest  = cursor\n",
    "    has_more = True\n",
    "    a=m=r=0\n",
    "\n",
    "    while has_more:\n",
    "        req_kwargs = dict(access_token=token, count=500,\n",
    "                          options=TransactionsSyncRequestOptions(include_personal_finance_category=False))\n",
    "        if latest: req_kwargs[\"cursor\"] = latest\n",
    "        resp = client.transactions_sync(TransactionsSyncRequest(**req_kwargs))\n",
    "\n",
    "        added    = resp[\"added\"]\n",
    "        modified = resp[\"modified\"]\n",
    "        removed  = resp[\"removed\"]\n",
    "\n",
    "        if not KEEP_PENDING:\n",
    "            added    = [t for t in added    if not t.get(\"pending\", False)]\n",
    "            modified = [t for t in modified if not t.get(\"pending\", False)]\n",
    "\n",
    "        def to_row(t):\n",
    "            return {\n",
    "                \"transaction_id\": t.get(\"transaction_id\"),\n",
    "                \"item_id\": item_id,\n",
    "                \"account_id\": t.get(\"account_id\"),\n",
    "                \"date\": t.get(\"date\"),\n",
    "                \"name\": t.get(\"name\"),\n",
    "                \"merchant_name\": t.get(\"merchant_name\"),\n",
    "                \"amount\": str(t.get(\"amount\")),\n",
    "                \"pending\": str(t.get(\"pending\", False)),\n",
    "            }\n",
    "        silver = upsert_rows(silver, [to_row(t) for t in added])\n",
    "        silver = upsert_rows(silver, [to_row(t) for t in modified])\n",
    "        silver = delete_rows(silver, removed)\n",
    "\n",
    "        latest = resp[\"next_cursor\"]; has_more = resp[\"has_more\"]\n",
    "        a += len(added); m += len(modified); r += len(removed)\n",
    "\n",
    "    next_cursors[item_id] = latest\n",
    "    total_added += a; total_modified += m; total_removed += r\n",
    "    print(f\"[{item_id}] +{a} / ~{m} / -{r} | cursor updated\")\n",
    "\n",
    "silver.to_csv(SILVER, index=False)\n",
    "cursors.update(next_cursors)\n",
    "with CURSORS_JSON.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"transactions\": cursors}, f, indent=2)\n",
    "print(f\"✔ Silver written ({len(silver)} rows) & cursors saved\")\n",
    "\n",
    "# ---------- STAGE 2: Silver → Gold (enrich) ----------\n",
    "def normalize_merchant_key(s: str) -> str:\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.upper()\n",
    "    s = re.sub(r\"[^A-Z0-9\\s]\", \" \", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "# Load YAML\n",
    "yaml_map = {\"merchants\": [], \"patterns\": []}\n",
    "if YAML_PATH.exists():\n",
    "    try:\n",
    "        yraw = yaml.safe_load(YAML_PATH.read_text(encoding=\"utf-8\")) or {}\n",
    "        yaml_map[\"merchants\"] = yraw.get(\"merchants\", []) or []\n",
    "        yaml_map[\"patterns\"]  = yraw.get(\"patterns\", []) or []\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ YAML parse issue:\", e)\n",
    "\n",
    "# Exact map\n",
    "exact_map = {}\n",
    "for m in yaml_map[\"merchants\"]:\n",
    "    key = normalize_merchant_key(m.get(\"match\",\"\"))\n",
    "    if key:\n",
    "        exact_map[key] = {\n",
    "            \"display_name_final\": m.get(\"display_name\") or key,\n",
    "            \"category_final\": m.get(\"category\") or \"\",\n",
    "            \"tags_final\": \",\".join(m.get(\"tags\", []) or []),\n",
    "            \"confidence_final\": \"yaml\",\n",
    "            \"source_final\": \"plaid\",\n",
    "        }\n",
    "\n",
    "# Regex rules\n",
    "regex_rules = []\n",
    "for p in yaml_map[\"patterns\"]:\n",
    "    rx = p.get(\"regex\")\n",
    "    if not rx: continue\n",
    "    try:\n",
    "        regex_rules.append((re.compile(rx, re.I), {\n",
    "            \"display_name_final\": p.get(\"display_name\") or \"\",\n",
    "            \"category_final\": p.get(\"category\") or \"\",\n",
    "            \"tags_final\": \",\".join(p.get(\"tags\", []) or []),\n",
    "            \"confidence_final\": \"yaml\",\n",
    "            \"source_final\": \"plaid\",\n",
    "        }))\n",
    "    except re.error as e:\n",
    "        print(\"⚠️ Bad regex skipped:\", rx, \"|\", e)\n",
    "\n",
    "# Types\n",
    "df = silver.copy()\n",
    "df[\"amount\"] = pd.to_numeric(df[\"amount\"], errors=\"coerce\")     # Plaid: outflows +, inflows -\n",
    "df[\"date\"]   = pd.to_datetime(df[\"date\"], errors=\"coerce\").dt.date\n",
    "\n",
    "# Description & merchant_key\n",
    "desc = df[\"merchant_name\"].fillna(\"\").replace(\"\", pd.NA).fillna(df[\"name\"])\n",
    "df[\"description\"] = desc\n",
    "df[\"merchant_key\"] = desc.apply(normalize_merchant_key)\n",
    "\n",
    "# Enrichment scaffold\n",
    "enriched = pd.DataFrame(index=df.index)\n",
    "for col in [\"display_name_final\",\"category_final\",\"tags_final\",\"confidence_final\",\"source_final\"]:\n",
    "    enriched[col] = \"\"\n",
    "enriched[\"source_final\"] = \"plaid\"\n",
    "\n",
    "# Exact matches\n",
    "mask_exact = df[\"merchant_key\"].isin(exact_map.keys())\n",
    "if mask_exact.any():\n",
    "    enriched.loc[mask_exact, [\"display_name_final\",\"category_final\",\"tags_final\",\"confidence_final\",\"source_final\"]] = \\\n",
    "        pd.DataFrame([exact_map[k] for k in df.loc[mask_exact, \"merchant_key\"]]).values\n",
    "\n",
    "# Regex matches for remaining blanks\n",
    "to_regex = enriched[\"display_name_final\"].eq(\"\")\n",
    "if to_regex.any() and regex_rules:\n",
    "    candidates = df.loc[to_regex, \"description\"].fillna(\"\")\n",
    "    rows = []\n",
    "    for i, text in candidates.items():\n",
    "        applied = False\n",
    "        for rx, mapping in regex_rules:\n",
    "            if rx.search(text or \"\"):\n",
    "                rows.append({\n",
    "                    \"display_name_final\": mapping[\"display_name_final\"] or df.at[i, \"merchant_key\"],\n",
    "                    \"category_final\": mapping[\"category_final\"],\n",
    "                    \"tags_final\": mapping[\"tags_final\"],\n",
    "                    \"confidence_final\": \"yaml\",\n",
    "                    \"source_final\": \"plaid\",\n",
    "                })\n",
    "                applied = True\n",
    "                break\n",
    "        if not applied:\n",
    "            rows.append({\"display_name_final\":\"\", \"category_final\":\"\", \"tags_final\":\"\", \"confidence_final\":\"\", \"source_final\":\"plaid\"})\n",
    "    enriched.loc[to_regex, [\"display_name_final\",\"category_final\",\"tags_final\",\"confidence_final\",\"source_final\"]] = \\\n",
    "        pd.DataFrame(rows).values\n",
    "\n",
    "# Fallback display_name\n",
    "still_blank = enriched[\"display_name_final\"].eq(\"\")\n",
    "enriched.loc[still_blank, \"display_name_final\"] = df.loc[still_blank, \"merchant_key\"]\n",
    "\n",
    "# Non-spend\n",
    "rx_non_spend = re.compile(\"|\".join([\n",
    "    r\"\\bPAYMENT\\b\", r\"\\bAUTOPAY\\b\", r\"\\bDIRECT\\s?PAY\\b\", r\"\\bCREDIT\\b\", r\"\\bREFUND\\b\",\n",
    "    r\"\\bTRANSFER\\b\", r\"\\bZELLE\\b\", r\"\\bVENMO\\b\", r\"\\bREVERSAL\\b\"\n",
    "]), re.I)\n",
    "is_non_spend = df[\"name\"].fillna(\"\").str.contains(rx_non_spend) | df[\"merchant_name\"].fillna(\"\").str.contains(rx_non_spend)\n",
    "is_non_spend = is_non_spend | (df[\"amount\"] < 0)\n",
    "\n",
    "# month_start as Python date\n",
    "s  = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "ms = (s.values.astype(\"datetime64[M]\")).astype(\"datetime64[D]\")\n",
    "month_start = pd.Series(pd.DatetimeIndex(ms).date, index=df.index)\n",
    "\n",
    "gold = pd.DataFrame({\n",
    "    \"date\": df[\"date\"],\n",
    "    \"account\": df[\"account_id\"].astype(str),\n",
    "    \"description\": df[\"name\"].astype(str),\n",
    "    \"merchant_key\": df[\"merchant_key\"].astype(str),\n",
    "    \"display_name_final\": enriched[\"display_name_final\"].astype(str),\n",
    "    \"category_final\": enriched[\"category_final\"].astype(str),\n",
    "    \"tags_final\": enriched[\"tags_final\"].astype(str),\n",
    "    \"confidence_final\": enriched[\"confidence_final\"].replace(\"\", \"plaid\"),\n",
    "    \"source_final\": enriched[\"source_final\"],\n",
    "    \"amount\": df[\"amount\"],\n",
    "    \"is_necessity\": False,\n",
    "    \"is_non_spend_flow\": is_non_spend.astype(bool),\n",
    "    \"month_start\": month_start,\n",
    "})\n",
    "\n",
    "gold.to_csv(ENRICHED, index=False)\n",
    "\n",
    "unknown_mask = (gold[\"category_final\"] == \"\") & (~gold[\"is_non_spend_flow\"])\n",
    "unknowns = gold.loc[unknown_mask, [\"merchant_key\",\"description\"]].drop_duplicates().sort_values(\"merchant_key\")\n",
    "unknowns.to_csv(UNKNOWN, index=False)\n",
    "\n",
    "# ---------- Summary ----------\n",
    "print(\"\\n=== RUN SUMMARY ===\")\n",
    "print(f\"Silver rows:  {len(silver):,}\")\n",
    "print(f\"Gold rows:    {len(gold):,}\")\n",
    "print(f\"Unknowns:     {len(unknowns):,}  → {UNKNOWN.name}\")\n",
    "print(f\"Wrote Gold:   {ENRICHED}\")\n",
    "print(f\"Cursors:      {CURSORS_JSON}\")\n",
    "print(f\"Deltas:       +{total_added} / ~{total_modified} / -{total_removed}\")\n",
    "print(\"✅ Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (AI Tools)",
   "language": "python",
   "name": "ai-tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
