{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffc52963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "from openai import OpenAI\n",
    "\n",
    "def load_azure_env():\n",
    "    repo = Path.cwd()\n",
    "    for p in [repo / \"scripts\" / \".env\", repo / \".env\"]:\n",
    "        if p.exists():\n",
    "            load_dotenv(p, override=True)\n",
    "    required = [\"AZURE_OPENAI_ENDPOINT\",\"AZURE_OPENAI_API_KEY\",\"AZURE_OPENAI_DEPLOYMENT\",\"AZURE_OPENAI_EMBEDDINGS\"]\n",
    "    missing = [k for k in required if not os.getenv(k)]\n",
    "    if missing:\n",
    "        print(\"Azure not configured; missing:\", \", \".join(missing))\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f445968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_chat_client():\n",
    "    return OpenAI(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        base_url=f\"{os.getenv('AZURE_OPENAI_ENDPOINT')}/openai/deployments/{os.getenv('AZURE_OPENAI_DEPLOYMENT')}\",\n",
    "        default_query={\"api-version\": os.getenv(\"AZURE_OPENAI_API_VERSION\",\"2024-02-15-preview\")},\n",
    "        default_headers={\"api-key\": os.getenv(\"AZURE_OPENAI_API_KEY\")},\n",
    "    )\n",
    "\n",
    "def azure_embed_client():\n",
    "    return OpenAI(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        base_url=f\"{os.getenv('AZURE_OPENAI_ENDPOINT')}/openai/deployments/{os.getenv('AZURE_OPENAI_EMBEDDINGS')}\",\n",
    "        default_query={\"api-version\": os.getenv(\"AZURE_OPENAI_API_VERSION\",\"2024-02-15-preview\")},\n",
    "        default_headers={\"api-key\": os.getenv(\"AZURE_OPENAI_API_KEY\")},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55a8770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merchant labeling (robust JSON, schema, UTC, CI-safe) ---\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import os, json, re, time\n",
    "from tenacity import retry, wait_exponential, stop_after_attempt\n",
    "\n",
    "MERCHANT_DIM_PATH = Path(\"config/merchants_dim.csv\")\n",
    "IN_CI = os.getenv(\"GITHUB_ACTIONS\", \"\").lower() == \"true\"\n",
    "AI_STRICT = os.getenv(\"AI_STRICT\", \"0\") == \"1\"  # set to 1 to fail on AI errors\n",
    "BATCH = 10 if IN_CI else 20     # smaller in CI to avoid truncation\n",
    "MAP_ALL = True\n",
    "\n",
    "SCHEMA = {\n",
    "    \"merchant_key\": \"string\",\n",
    "    \"display_name\": \"string\",\n",
    "    \"category\": \"string\",\n",
    "    \"subcategory\": \"string\",\n",
    "    \"tags\": \"string\",\n",
    "    \"source\": \"string\",\n",
    "    \"confidence\": \"float64\",\n",
    "    \"last_updated\": \"string\",\n",
    "}\n",
    "\n",
    "def _ensure_merchants_dim():\n",
    "    if MERCHANT_DIM_PATH.exists():\n",
    "        md = pd.read_csv(MERCHANT_DIM_PATH)\n",
    "        for col, dt in SCHEMA.items():\n",
    "            if col not in md.columns:\n",
    "                md[col] = pd.Series(dtype=dt)\n",
    "        return md.astype(SCHEMA, copy=False)\n",
    "    MERCHANT_DIM_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    return pd.DataFrame({c: pd.Series(dtype=dt) for c, dt in SCHEMA.items()})\n",
    "\n",
    "def _parse_labels_strict_or_salvage(txt: str):\n",
    "    txt = txt.strip()\n",
    "    try:\n",
    "        obj = json.loads(txt)\n",
    "        if isinstance(obj, dict) and isinstance(obj.get(\"items\"), list):\n",
    "            return obj[\"items\"]\n",
    "        if isinstance(obj, list):\n",
    "            return obj\n",
    "    except Exception:\n",
    "        pass\n",
    "    m = re.findall(r\"\\[[\\s\\S]*\\]\", txt)\n",
    "    if m:\n",
    "        for cand in reversed(m):\n",
    "            try:\n",
    "                return json.loads(cand)\n",
    "            except Exception:\n",
    "                continue\n",
    "    raise RuntimeError(f\"Failed to parse AI JSON (first 400 chars):\\n{txt[:400]}\")\n",
    "\n",
    "@retry(wait=wait_exponential(multiplier=1, min=1, max=20), stop=stop_after_attempt(5))\n",
    "def azure_label_batch(keys_batch):\n",
    "    compact = [str(k)[:100] for k in keys_batch]\n",
    "    sys_prompt = (\n",
    "        \"You label merchant identifiers for a personal finance dashboard.\\n\"\n",
    "        \"For each merchant_key, produce: merchant_key, display_name, category, subcategory, tags.\\n\"\n",
    "        \"- display_name: short human name (e.g., 'ARCO', 'Apple Card').\\n\"\n",
    "        \"- category: one of Dining, Groceries, Gas, Shopping, Utilities, Subscriptions, Transfers, Income, \"\n",
    "        \"Health, Travel, Entertainment, Education, Fees, Misc.\\n\"\n",
    "        \"- subcategory: specific subtype (e.g., 'Gas Station', 'Internet Service').\\n\"\n",
    "        \"- tags: array of 1–5 lowercase keywords.\\n\"\n",
    "        'Return ONLY JSON: {\"items\":[{...}]} with no extra commentary.'\n",
    "    )\n",
    "    usr_payload = {\"merchant_keys\": compact}\n",
    "    c = azure_chat_client()\n",
    "    r = c.chat.completions.create(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        messages=[\n",
    "            {\"role\":\"system\",\"content\": sys_prompt},\n",
    "            {\"role\":\"user\",\"content\": json.dumps(usr_payload)}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1400,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "    return _parse_labels_strict_or_salvage(r.choices[0].message.content)\n",
    "\n",
    "def label_new_merchants(df, merchant_key_col=\"merchant_key\"):\n",
    "    md = _ensure_merchants_dim()\n",
    "    if merchant_key_col not in df.columns:\n",
    "        print(f\"Column '{merchant_key_col}' not in dataframe; skipping labeling.\")\n",
    "        return 0\n",
    "\n",
    "    known = set(md[\"merchant_key\"].astype(str)) if len(md) > 0 else set()\n",
    "    candidates = sorted(set(df[merchant_key_col].astype(str)) - known)\n",
    "    if not MAP_ALL or not candidates:\n",
    "        print(\"No new merchants to label.\"); return 0\n",
    "\n",
    "    added = 0\n",
    "    for i in range(0, len(candidates), BATCH):\n",
    "        batch = candidates[i:i+BATCH]\n",
    "        try:\n",
    "            items = azure_label_batch(batch)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ AI batch failed [{i}:{i+len(batch)}] — {e}\")\n",
    "            if AI_STRICT:\n",
    "                raise\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        now = datetime.now(timezone.utc).isoformat()\n",
    "        rows = []\n",
    "        for it in items:\n",
    "            mk = str(it.get(\"merchant_key\") or \"\").strip()\n",
    "            if not mk:\n",
    "                continue\n",
    "            display = str(it.get(\"display_name\", mk)).upper().strip()\n",
    "            category = str(it.get(\"category\",\"\")).strip()\n",
    "            subcat   = str(it.get(\"subcategory\",\"\")).strip()\n",
    "            tags_val = it.get(\"tags\", [])\n",
    "            tags_csv = \",\".join([str(t).strip() for t in tags_val]) if isinstance(tags_val, list) else \"\"\n",
    "            rows.append({\n",
    "                \"merchant_key\": mk,\n",
    "                \"display_name\": display,\n",
    "                \"category\": category,\n",
    "                \"subcategory\": subcat,\n",
    "                \"tags\": tags_csv,\n",
    "                \"source\": \"azure\",\n",
    "                \"confidence\": 0.90,\n",
    "                \"last_updated\": now\n",
    "            })\n",
    "\n",
    "        if rows:\n",
    "            chunk = pd.DataFrame(rows)\n",
    "            for col, dt in SCHEMA.items():\n",
    "                if col not in chunk.columns:\n",
    "                    chunk[col] = pd.Series(dtype=dt)\n",
    "            chunk = chunk.astype(SCHEMA, copy=False)\n",
    "            md = md.astype(SCHEMA, copy=False)\n",
    "\n",
    "            md = pd.concat([md, chunk], ignore_index=True)\n",
    "            md = md.sort_values(\"last_updated\").drop_duplicates([\"merchant_key\"], keep=\"last\")\n",
    "            md.to_csv(MERCHANT_DIM_PATH, index=False)\n",
    "            added += len(chunk)\n",
    "            print(f\"Added {len(chunk)} merchant mappings (running total {added}).\")\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    return added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "36e65242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Embeddings builder (caches to vectorstore/embeddings.parquet) ---\n",
    "\n",
    "import numpy as np, pyarrow as pa, pyarrow.parquet as pq\n",
    "\n",
    "VECTOR_PATH = Path(\"vectorstore/embeddings.parquet\")\n",
    "EMBED_ROWS = 500\n",
    "\n",
    "def build_embeddings(df, text_cols=(\"display_name\",\"description\")):\n",
    "    ec = azure_embed_client()\n",
    "    cols = [c for c in text_cols if c in df.columns]\n",
    "    if not cols:\n",
    "        print(\"No text columns found; skipping embeddings.\"); return 0\n",
    "\n",
    "    recent = df.tail(EMBED_ROWS).copy()\n",
    "    texts = recent[cols[0]].astype(str)\n",
    "    for c in cols[1:]:\n",
    "        texts = texts + \" | \" + recent[c].astype(str)\n",
    "    texts = texts.tolist()\n",
    "\n",
    "    embs = []\n",
    "    for t in texts:\n",
    "        e = ec.embeddings.create(model=os.getenv(\"AZURE_OPENAI_EMBEDDINGS\"), input=[t])\n",
    "        embs.append(e.data[0].embedding)\n",
    "\n",
    "    if not embs:\n",
    "        print(\"No embeddings produced.\"); return 0\n",
    "    dim = len(embs[0])\n",
    "\n",
    "    flat = np.array(embs, dtype=\"float32\").ravel()\n",
    "    arr = pa.FixedSizeListArray.from_arrays(pa.array(flat), dim)\n",
    "    table = pa.Table.from_pydict({\"row_idx\": pa.array(recent.index.astype(int)), \"embedding\": arr})\n",
    "    VECTOR_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    pq.write_table(table, VECTOR_PATH)\n",
    "    print(f\"Wrote {len(embs)} embeddings (dim {dim}) → {VECTOR_PATH}\")\n",
    "    return len(embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71c212fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_ai_enabled():\n",
    "    req = [\"AZURE_OPENAI_ENDPOINT\",\"AZURE_OPENAI_API_KEY\",\"AZURE_OPENAI_DEPLOYMENT\",\"AZURE_OPENAI_EMBEDDINGS\"]\n",
    "    return all(os.getenv(k) for k in req)\n",
    "\n",
    "def run_azure_ai(enriched_df):\n",
    "    if not load_azure_env() or not azure_ai_enabled():\n",
    "        print(\"Azure not configured; skipping AI steps.\")\n",
    "        return {\"labeled\":0,\"embedded\":0}\n",
    "    labeled = label_new_merchants(enriched_df)\n",
    "    embedded = build_embeddings(enriched_df)\n",
    "    return {\"labeled\": labeled, \"embedded\": embedded}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
