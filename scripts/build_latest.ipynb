{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env OK â†’ PLAID_CLIENT_ID: 68bbâ€¦6689 | PLAID_SECRET: a605â€¦7df5 | PLAID_ENV: production | OUTPUT_DIR: C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\raw | TOKENS_PATH: C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\.state\\access_tokens.json\n",
      "Loaded 3 token(s).\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Env, paths, .env loader, tokens (robust) ---\n",
    "import os, json, re\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Optional dotenv\n",
    "try:\n",
    "    from dotenv import load_dotenv, find_dotenv\n",
    "except Exception:\n",
    "    load_dotenv = None\n",
    "    find_dotenv = None\n",
    "\n",
    "def mask(s: str | None) -> str:\n",
    "    if not s: return \"<missing>\"\n",
    "    return (s[:4] + \"â€¦\" + s[-4:]) if len(s) > 8 else \"***\"\n",
    "\n",
    "# Resolve repo root (works from / or /scripts)\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root = next((p for p in [cwd, *cwd.parents] if (p / \".git\").exists() or p.name == \"spending-dashboard\"), cwd)\n",
    "\n",
    "# Load .env if present (scripts/.env preferred)\n",
    "def load_envs():\n",
    "    if load_dotenv is None:\n",
    "        return\n",
    "    # explicit override via ENV_PATH, else standard locations\n",
    "    abs_override = os.getenv(\"ENV_PATH\", str(repo_root / \"scripts\" / \".env\"))\n",
    "    if abs_override and Path(abs_override).exists():\n",
    "        try:\n",
    "            load_dotenv(abs_override, override=False, encoding=\"utf-8\")\n",
    "        except TypeError:\n",
    "            load_dotenv(abs_override, override=False)\n",
    "    for p in [\n",
    "        repo_root / \"scripts\" / \".env\",\n",
    "        repo_root / \".env\",\n",
    "        repo_root / \"config\" / \".env\",\n",
    "        cwd / \".env\",\n",
    "    ]:\n",
    "        if Path(p).exists():\n",
    "            try:\n",
    "                load_dotenv(str(p), override=False, encoding=\"utf-8\")\n",
    "            except TypeError:\n",
    "                load_dotenv(str(p), override=False)\n",
    "    if find_dotenv:\n",
    "        found = find_dotenv(usecwd=True)\n",
    "        if found:\n",
    "            try:\n",
    "                load_dotenv(found, override=False, encoding=\"utf-8\")\n",
    "            except TypeError:\n",
    "                load_dotenv(found, override=False)\n",
    "\n",
    "load_envs()\n",
    "\n",
    "# Normalize env\n",
    "PLAID_CLIENT_ID = os.getenv(\"PLAID_CLIENT_ID\")\n",
    "PLAID_SECRET    = os.getenv(\"PLAID_SECRET\")\n",
    "PLAID_ENV       = (os.getenv(\"PLAID_ENV\", \"production\") or \"production\").strip().lower()\n",
    "alias = {\"prod\":\"production\",\"live\":\"production\",\"dev\":\"development\",\"devel\":\"development\",\"sb\":\"sandbox\"}\n",
    "PLAID_ENV = alias.get(PLAID_ENV, PLAID_ENV)\n",
    "if PLAID_ENV not in {\"production\",\"development\",\"sandbox\"}:\n",
    "    PLAID_ENV = \"production\"\n",
    "\n",
    "# Paths (env-overridable)\n",
    "OUTPUT_DIR = Path(os.getenv(\"OUTPUT_DIR\", str(repo_root / \"data\" / \"raw\")))\n",
    "STATE_DIR  = Path(os.getenv(\"STATE_DIR\",  str(repo_root / \".state\")))\n",
    "TOKENS_PATH = Path(os.getenv(\"TOKENS_PATH\", str(STATE_DIR / \"access_tokens.json\")))\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "STATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Load & validate access tokens (env > file), canonical-only ---\n",
    "def _strip_bom(s: str) -> str:\n",
    "    return s.lstrip(\"\\ufeff\") if isinstance(s, str) else s\n",
    "\n",
    "def _parse_pairs_blob(blob: str) -> dict:\n",
    "    # Accept separators ; , | or newlines, and k=v or k:v\n",
    "    raw = [p.strip() for sep in [\"\\n\",\";\",\"|\",\",\"] for p in (blob.split(sep) if sep in blob else []) if p.strip()]\n",
    "    if not raw: raw = [blob.strip()]\n",
    "    out = {}\n",
    "    for p in raw:\n",
    "        if \"=\" in p:\n",
    "            k, v = p.split(\"=\", 1)\n",
    "        elif \":\" in p:\n",
    "            k, v = p.split(\":\", 1)\n",
    "        else:\n",
    "            continue\n",
    "        k = k.strip().strip('\"').strip(\"'\")\n",
    "        v = v.strip().strip('\"').strip(\"'\")\n",
    "        if k and v:\n",
    "            out[k] = v\n",
    "    return out\n",
    "\n",
    "def _normalize_tokens(obj) -> dict:\n",
    "    if isinstance(obj, dict):\n",
    "        return {str(k): str(v).strip() for k,v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        out = {}\n",
    "        for item in obj:\n",
    "            if isinstance(item, dict):\n",
    "                name = item.get(\"issuer\") or item.get(\"bank\") or item.get(\"name\")\n",
    "                token = item.get(\"access_token\") or item.get(\"token\")\n",
    "                if name and token:\n",
    "                    out[str(name)] = str(token).strip()\n",
    "        return out\n",
    "    if isinstance(obj, str):\n",
    "        s = _strip_bom(obj).strip()\n",
    "        # JSON first\n",
    "        try:\n",
    "            parsed = json.loads(s)\n",
    "            return _normalize_tokens(parsed)\n",
    "        except Exception:\n",
    "            # pairs fallback\n",
    "            return _parse_pairs_blob(s)\n",
    "    return {}\n",
    "\n",
    "def load_access_tokens():\n",
    "    # 1) env\n",
    "    blob = os.getenv(\"PLAID_ACCESS_TOKENS\", \"\").strip()\n",
    "    if blob:\n",
    "        tokens = _normalize_tokens(blob)\n",
    "        if tokens:\n",
    "            return tokens\n",
    "    # 2) file\n",
    "    if TOKENS_PATH.exists():\n",
    "        raw = TOKENS_PATH.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        tokens = _normalize_tokens(raw)\n",
    "        if tokens:\n",
    "            return tokens\n",
    "    raise AssertionError(\n",
    "        f\"Could not load access tokens. Provide PLAID_ACCESS_TOKENS env or a valid JSON at {TOKENS_PATH}.\"\n",
    "    )\n",
    "\n",
    "ACCESS_TOKENS = load_access_tokens()\n",
    "\n",
    "# Canonical format guard: access-<env>-<identifier> (lowercase letters/digits/hyphens; no / + =)\n",
    "PAT = re.compile(r\"^access-(?:production|development|sandbox)-[a-z0-9\\-]+$\")\n",
    "expected_prefix = f\"access-{PLAID_ENV}-\"\n",
    "bad = [k for k,v in ACCESS_TOKENS.items() if not isinstance(v, str) or not v.startswith(expected_prefix) or not PAT.match(v)]\n",
    "assert not bad, f\"Non-canonical or wrong-env tokens for: {bad}. Ensure tokens look like '{expected_prefix}â€¦' (no '/', '+', '=').\"\n",
    "\n",
    "print(\n",
    "    \"Env OK â†’\",\n",
    "    \"PLAID_CLIENT_ID:\", mask(PLAID_CLIENT_ID),\n",
    "    \"| PLAID_SECRET:\", mask(PLAID_SECRET),\n",
    "    \"| PLAID_ENV:\", PLAID_ENV,\n",
    "    \"| OUTPUT_DIR:\", str(OUTPUT_DIR),\n",
    "    \"| TOKENS_PATH:\", str(TOKENS_PATH),\n",
    ")\n",
    "print(f\"Loaded {len(ACCESS_TOKENS)} token(s).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a22fe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plaid SDK: v10+ (plaid_api)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Plaid client init (v10+ preferred, legacy fallback) ---\n",
    "USE_PLAID_V10 = False\n",
    "client = None\n",
    "\n",
    "try:\n",
    "    # v10+ path\n",
    "    from plaid.api import plaid_api\n",
    "    from plaid.configuration import Configuration\n",
    "    try:\n",
    "        from plaid.configuration import Environment  # newer enum\n",
    "        env_host = {\n",
    "            \"production\":  Environment.Production,\n",
    "            \"development\": Environment.Development,\n",
    "            \"sandbox\":     Environment.Sandbox,\n",
    "        }[PLAID_ENV]\n",
    "        config = Configuration(host=env_host)\n",
    "    except Exception:\n",
    "        # fallback if Environment enum not present\n",
    "        host_url = {\n",
    "            \"production\":  \"https://production.plaid.com\",\n",
    "            \"development\": \"https://development.plaid.com\",\n",
    "            \"sandbox\":     \"https://sandbox.plaid.com\",\n",
    "        }[PLAID_ENV]\n",
    "        config = Configuration(host=host_url)\n",
    "\n",
    "    from plaid.api_client import ApiClient\n",
    "    config.api_key[\"clientId\"] = PLAID_CLIENT_ID\n",
    "    config.api_key[\"secret\"]   = PLAID_SECRET\n",
    "    api_client = ApiClient(config)\n",
    "    client = plaid_api.PlaidApi(api_client)\n",
    "    USE_PLAID_V10 = True\n",
    "    print(\"Plaid SDK: v10+ (plaid_api)\")\n",
    "except Exception as e_v10:\n",
    "    try:\n",
    "        # legacy path\n",
    "        from plaid import Client as LegacyClient\n",
    "        client = LegacyClient(\n",
    "            client_id=PLAID_CLIENT_ID,\n",
    "            secret=PLAID_SECRET,\n",
    "            environment=PLAID_ENV\n",
    "        )\n",
    "        USE_PLAID_V10 = False\n",
    "        print(\"Plaid SDK: legacy Client()\")\n",
    "    except Exception as e_legacy:\n",
    "        raise ImportError(\n",
    "            \"Could not initialize Plaid client. Ensure 'plaid-python' is installed. \"\n",
    "            f\"v10 error: {e_v10}\\nlegacy error: {e_legacy}\"\n",
    "        )\n",
    "\n",
    "# Optional quick probe (set PRECHECK=1 to enable)\n",
    "if os.getenv(\"PRECHECK\", \"0\") == \"1\" and USE_PLAID_V10:\n",
    "    from plaid.model.accounts_get_request import AccountsGetRequest\n",
    "    from plaid.api_client import ApiException\n",
    "    for issuer, tok in ACCESS_TOKENS.items():\n",
    "        try:\n",
    "            n = len(client.accounts_get(AccountsGetRequest(access_token=tok)).to_dict().get(\"accounts\", []))\n",
    "            print(f\"{issuer}: âœ… accounts_get OK ({n} accounts)\")\n",
    "        except ApiException as e:\n",
    "            print(f\"{issuer}: âŒ API {e.status} -> {getattr(e, 'body', e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd6aee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Fetching Discover (2025-06-11 â†’ 2025-09-09)â€¦\n",
      "   â†’ 29 rows\n",
      "ðŸ”„ Fetching Petal (2025-06-11 â†’ 2025-09-09)â€¦\n",
      "   â†’ 27 rows\n",
      "ðŸ”„ Fetching Silver State Schools Credit Union (2025-06-11 â†’ 2025-09-09)â€¦\n",
      "   â†’ 91 rows\n",
      "âœ… Pulled total 147 transactions across 3 bank(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosis\\AppData\\Local\\Temp\\ipykernel_14084\\2122629215.py:66: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined = pd.concat(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>account_owner</th>\n",
       "      <th>amount</th>\n",
       "      <th>authorized_date</th>\n",
       "      <th>authorized_datetime</th>\n",
       "      <th>category</th>\n",
       "      <th>category_id</th>\n",
       "      <th>check_number</th>\n",
       "      <th>counterparties</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>pending_transaction_id</th>\n",
       "      <th>personal_finance_category</th>\n",
       "      <th>personal_finance_category_icon_url</th>\n",
       "      <th>transaction_code</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>unofficial_currency_code</th>\n",
       "      <th>website</th>\n",
       "      <th>bank_name</th>\n",
       "      <th>card_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB</td>\n",
       "      <td>None</td>\n",
       "      <td>60.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'Bullet Legal Servi', 'type': 'merch...</td>\n",
       "      <td>2025-09-09</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'confidence_level': 'LOW', 'detailed': 'GENER...</td>\n",
       "      <td>https://plaid-category-icons.plaid.com/PFC_GEN...</td>\n",
       "      <td>None</td>\n",
       "      <td>ekDppAQbzvHjDZMJEaRgH9r8V8xARYTejoKpd</td>\n",
       "      <td>place</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Discover</td>\n",
       "      <td>Discover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'confidence_level': 'VERY_HIGH', 'detailed': ...</td>\n",
       "      <td>https://plaid-category-icons.plaid.com/PFC_GEN...</td>\n",
       "      <td>None</td>\n",
       "      <td>YdXEEwaoQxsgvK9qePDdfbpekeq83NHprjbyJ</td>\n",
       "      <td>place</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Discover</td>\n",
       "      <td>Discover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB</td>\n",
       "      <td>None</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'confidence_level': 'VERY_HIGH', 'detailed': ...</td>\n",
       "      <td>https://plaid-category-icons.plaid.com/PFC_GEN...</td>\n",
       "      <td>None</td>\n",
       "      <td>mxkEEJQ8drir06dPjE5nU5A1R1aqOmC4dYPXv</td>\n",
       "      <td>place</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Discover</td>\n",
       "      <td>Discover</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               account_id account_owner  amount  \\\n",
       "0  MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB          None    60.0   \n",
       "1  MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB          None    -1.0   \n",
       "2  MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB          None    -1.0   \n",
       "\n",
       "  authorized_date authorized_datetime category category_id check_number  \\\n",
       "0            None                None     None        None         None   \n",
       "1            None                None     None        None         None   \n",
       "2            None                None     None        None         None   \n",
       "\n",
       "                                      counterparties        date  ...  \\\n",
       "0  [{'name': 'Bullet Legal Servi', 'type': 'merch...  2025-09-09  ...   \n",
       "1                                                 []  2025-09-06  ...   \n",
       "2                                                 []  2025-09-06  ...   \n",
       "\n",
       "  pending_transaction_id                          personal_finance_category  \\\n",
       "0                   None  {'confidence_level': 'LOW', 'detailed': 'GENER...   \n",
       "1                   None  {'confidence_level': 'VERY_HIGH', 'detailed': ...   \n",
       "2                   None  {'confidence_level': 'VERY_HIGH', 'detailed': ...   \n",
       "\n",
       "                  personal_finance_category_icon_url transaction_code  \\\n",
       "0  https://plaid-category-icons.plaid.com/PFC_GEN...             None   \n",
       "1  https://plaid-category-icons.plaid.com/PFC_GEN...             None   \n",
       "2  https://plaid-category-icons.plaid.com/PFC_GEN...             None   \n",
       "\n",
       "                          transaction_id transaction_type  \\\n",
       "0  ekDppAQbzvHjDZMJEaRgH9r8V8xARYTejoKpd            place   \n",
       "1  YdXEEwaoQxsgvK9qePDdfbpekeq83NHprjbyJ            place   \n",
       "2  mxkEEJQ8drir06dPjE5nU5A1R1aqOmC4dYPXv            place   \n",
       "\n",
       "  unofficial_currency_code website bank_name  card_name  \n",
       "0                     None    None  Discover   Discover  \n",
       "1                     None    None  Discover   Discover  \n",
       "2                     None    None  Discover   Discover  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Cell 3: Pull & consolidate transactions across all banks ---\n",
    "DAYS_BACK = int(os.getenv(\"DAYS_BACK\", \"90\"))\n",
    "end_date = date.today()\n",
    "start_date = end_date - timedelta(days=DAYS_BACK)\n",
    "\n",
    "all_frames: list[pd.DataFrame] = []\n",
    "\n",
    "if USE_PLAID_V10:\n",
    "    from plaid.model.transactions_get_request import TransactionsGetRequest\n",
    "\n",
    "    def fetch_transactions(bank_name: str, access_token: str) -> pd.DataFrame:\n",
    "        txns = []\n",
    "        offset = 0\n",
    "        while True:\n",
    "            req = TransactionsGetRequest(\n",
    "                access_token=access_token,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                options={\"count\": 500, \"offset\": offset}\n",
    "            )\n",
    "            resp = client.transactions_get(req).to_dict()\n",
    "            txns.extend(resp.get(\"transactions\", []))\n",
    "            total = resp.get(\"total_transactions\", 0)\n",
    "            if len(txns) >= total:\n",
    "                break\n",
    "            offset = len(txns)\n",
    "            if offset > 50_000:\n",
    "                raise RuntimeError(f\"Pagination runaway for {bank_name}\")\n",
    "        df = pd.DataFrame(txns)\n",
    "        if not df.empty:\n",
    "            df[\"bank_name\"] = bank_name\n",
    "            df[\"card_name\"] = bank_name  # TEMP: equals bank_name; later we can map account_id â†’ exact card\n",
    "        return df\n",
    "else:\n",
    "    def fetch_transactions(bank_name: str, access_token: str) -> pd.DataFrame:\n",
    "        txns = []\n",
    "        offset = 0\n",
    "        while True:\n",
    "            resp = client.Transactions.get(\n",
    "                access_token=access_token,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                options={\"count\": 500, \"offset\": offset}\n",
    "            )\n",
    "            total = resp[\"total_transactions\"]\n",
    "            txns.extend(resp[\"transactions\"])\n",
    "            if len(txns) >= total:\n",
    "                break\n",
    "            offset = len(txns)\n",
    "            if offset > 50_000:\n",
    "                raise RuntimeError(f\"Pagination runaway for {bank_name}\")\n",
    "        df = pd.DataFrame(txns)\n",
    "        if not df.empty:\n",
    "            df[\"bank_name\"] = bank_name\n",
    "            df[\"card_name\"] = bank_name  # TEMP: equals bank_name; later we can map account_id â†’ exact card\n",
    "        return df\n",
    "\n",
    "# Pull each bank\n",
    "for bank_name, token in ACCESS_TOKENS.items():\n",
    "    print(f\"ðŸ”„ Fetching {bank_name} ({start_date} â†’ {end_date})â€¦\")\n",
    "    df_bank = fetch_transactions(bank_name, token)\n",
    "    print(f\"   â†’ {len(df_bank):,} rows\")\n",
    "    all_frames.append(df_bank)\n",
    "\n",
    "# Combine\n",
    "combined = pd.concat(\n",
    "    [df for df in all_frames if df is not None and not df.empty],\n",
    "    ignore_index=True\n",
    ") if all_frames else pd.DataFrame()\n",
    "\n",
    "print(f\"âœ… Pulled total {0 if combined.empty else len(combined):,} transactions across {len(ACCESS_TOKENS)} bank(s).\")\n",
    "combined.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e7e92dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\raw\\latest.csv\n",
      "\n",
      "Preview (top 10):\n",
      "      date                                                                                                                                                        name          merchant_name category  amount payment_channel  pending                             account_id                        transaction_id                         bank_name\n",
      "2025-09-09                                                                                                                                      IN *BULLET LEGAL SERVI     Bullet Legal Servi     None   60.00        in store     True MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB ekDppAQbzvHjDZMJEaRgH9r8V8xARYTejoKpd                          Discover\n",
      "2025-09-09                             Withdrawal ALLY / TYPE: ALLY PAYMT ID: 9833122002 CO: ALLY NAME: Kosisonna Ugochukw %% ACH ECC WEB %% ACH Trace 021000021948953                   None     None  504.22           other    False  gN6YZzQRNzSopryjzYN1IBPAD8pzr1t8D5wwJ ON1Y8Q39NQSwm78MOj53CmqdMPeVXjSp4jo7N Silver State Schools Credit Union\n",
      "2025-09-08                                                                                                                          POS Signature Purchase using Token                   None     None   11.75        in store    False  gNvLDRDj5jt8kzgKweR5UBRg5rVrKDU6dgO1x vz94YJYENEF1Lnpe6Pa5fpnBDgwQqACkavEdM                             Petal\n",
      "2025-09-08 Withdrawal AMEX EPAYMENT / TYPE: ACH PMT ID: 0005000008 DATA: ER AM CO: AMEX EPAYMENT NAME: KOSISONNA UGOCHUKWU %% ACH ECC WEB %% ACH Trace 091000011489512                   None     None  777.78           other    False  gN6YZzQRNzSopryjzYN1IBPAD8pzr1t8D5wwJ ExM8nN93xNTvBeoEjPNMIAJeQRLKzqCdE46K8 Silver State Schools Credit Union\n",
      "2025-09-08                                                             Deposit Kiosk / WEALTHFRONT BROKERAGE LLC/WELLS FARGO BANK, NA/c1d31e5cf13740a1a7f434a251cbcfcd            Wealthfront     None -500.00           other    False  gN6YZzQRNzSopryjzYN1IBPAD8pzr1t8D5wwJ M7LV8Zqo7ZcYQXz6Zm5NUqb6Z3EM7Ys0P6dAP Silver State Schools Credit Union\n",
      "2025-09-07                              Withdrawal Signature base / APPLE CASH SENT MONEY 1INFINITELOOP CA Date 09/06/25 24055235250470441855705 4829 %% Card 25 #0695                   None     None    9.00           other    False  gN6YZzQRNzSopryjzYN1IBPAD8pzr1t8D5wwJ RNBY8jkQNjSDA6meRaMVhJ0LMav4dVt91aV6B Silver State Schools Credit Union\n",
      "2025-09-06                                                                                                                                                       Plaid                   None     None   -1.00           other     True MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB YdXEEwaoQxsgvK9qePDdfbpekeq83NHprjbyJ                          Discover\n",
      "2025-09-06                                                                                                                                  SP DILOHOME.COM 2156459070               Dilohome     None   21.36          online    False MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB NY3aa0BXo6tXQdk39b8LSaDgAg0ObPFbKnkVY                          Discover\n",
      "2025-09-06                                                                                                                                                       Plaid Plaid Technologies Inc     None    1.00        in store     True MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB zYaMMnQEAjtqB0Owd7KkIeAa3aPZmYhB4YQoM                          Discover\n",
      "2025-09-06                                                                                                                                                       Plaid Plaid Technologies Inc     None    1.00        in store     True MeB44vqbEwfQ5YJEbVR8UqrD3J9VKwFge99waB dKLppkzj54cYa8LR0PEgCqj8p8DE7Au19pRBy                          Discover\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Clean -> write latest.csv (+ sanity) ---\n",
    "# Light cleaning/schema for Power BI\n",
    "if not combined.empty:\n",
    "    combined[\"date\"] = pd.to_datetime(combined[\"date\"], errors=\"coerce\").dt.date\n",
    "    keep_cols = [\n",
    "        \"date\",\n",
    "        \"name\",\n",
    "        \"merchant_name\",\n",
    "        \"category\",\n",
    "        \"amount\",\n",
    "        \"payment_channel\",\n",
    "        \"pending\",\n",
    "        \"account_id\",\n",
    "        \"transaction_id\",\n",
    "        \"bank_name\",\n",
    "    ]\n",
    "    combined = combined[[c for c in keep_cols if c in combined.columns]]\n",
    "    combined = combined.sort_values(\"date\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Write output\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "latest_path = OUTPUT_DIR / \"latest.csv\"\n",
    "combined.to_csv(latest_path, index=False)\n",
    "\n",
    "# Sanity\n",
    "assert latest_path.exists(), \"latest.csv was not written.\"\n",
    "if not combined.empty:\n",
    "    assert \"bank_name\" in combined.columns, \"bank_name column missing.\"\n",
    "\n",
    "print(\"âœ… Saved:\", latest_path)\n",
    "try:\n",
    "    print(\"\\nPreview (top 10):\")\n",
    "    print(combined.head(10).to_string(index=False))\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e16b1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "def merchant_key_from(name: str) -> str:\n",
    "    s = (name or \"\").upper()\n",
    "    s = re.sub(r\"APPLE PAY ENDING IN \\d{4}\", \"\", s)\n",
    "    s = re.sub(r\"#\\d{2,}\", \"\", s)              # strip store numbers like #1234\n",
    "    s = re.sub(r\"\\d+\", \"\", s)                  # kill stray digits\n",
    "    s = re.sub(r\"[^A-Z&\\s]\", \" \", s)           # keep letters, ampersand, spaces\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def apply_yaml_mapping(df: pd.DataFrame, ymap: dict) -> pd.DataFrame:\n",
    "    if not ymap:\n",
    "        return df\n",
    "    look = {k.upper(): v for k, v in ymap.items()}\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        mk = r.get(\"merchant_key\", \"\")\n",
    "        m = look.get(mk, {})\n",
    "        rows.append({\n",
    "            **r,\n",
    "            \"display_name_final\": m.get(\"display_name\", r.get(\"merchant_name\") or r.get(\"name\")),\n",
    "            \"category_final\":     m.get(\"category\"),\n",
    "            \"subcategory_final\":  m.get(\"subcategory\"),\n",
    "            \"tags_final\":         \",\".join(m.get(\"tags\", [])) if isinstance(m.get(\"tags\", []), (list, tuple)) else m.get(\"tags\"),\n",
    "            \"confidence_final\":   m.get(\"confidence\", \"map\"),\n",
    "            \"source_final\":       \"yaml\"\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def mark_non_spend_flows(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pats = [\n",
    "        r\"PAYMENT\", r\"TRANSFER\", r\"ACH\", r\"ZELLE\", r\"DIRECTPAY\", r\"CREDIT\",\n",
    "        r\"REFUND\", r\"REIMBURSE\", r\"ADJUSTMENT\", r\"REVERSAL\"\n",
    "    ]\n",
    "    pat = re.compile(\"|\".join(pats))\n",
    "    names = (df[\"name\"].fillna(\"\") + \" \" + df[\"merchant_name\"].fillna(\"\")).str.upper()\n",
    "    df[\"is_non_spend_flow\"] = names.str.contains(pat)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e3c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a robust merchant key\n",
    "combined[\"merchant_key\"] = combined[\"merchant_name\"].fillna(combined[\"name\"]).map(merchant_key_from)\n",
    "\n",
    "# Load YAML map if exists\n",
    "PATH_YAML = Path(\"../config/categories.yaml\")\n",
    "ymap = {}\n",
    "if PATH_YAML.exists():\n",
    "    with open(PATH_YAML, \"r\") as f:\n",
    "        ymap = yaml.safe_load(f) or {}\n",
    "\n",
    "# Apply mapping + mark non-spend flows\n",
    "enriched = apply_yaml_mapping(combined, ymap)\n",
    "enriched = mark_non_spend_flows(enriched)\n",
    "\n",
    "# Keep stable columns for Power BI\n",
    "cols = [\n",
    "    \"date\",\"name\",\"merchant_name\",\"merchant_key\",\"category\",\"amount\",\"bank_name\", \"card_name\"\n",
    "    \"display_name_final\",\"category_final\",\"subcategory_final\",\"tags_final\",\n",
    "    \"is_non_spend_flow\",\"confidence_final\",\"source_final\"\n",
    "]\n",
    "enriched = enriched.reindex(columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "114c6633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Latest CSV saved â†’ C:\\Users\\kosis\\Downloads\\Automation\\spending-dashboard\\data\\raw\\latest.csv  rows=147\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "latest_path = OUTPUT_DIR / \"latest.csv\"\n",
    "enriched.to_csv(latest_path, index=False)\n",
    "print(f\"âœ… Latest CSV saved â†’ {latest_path}  rows={len(enriched)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
